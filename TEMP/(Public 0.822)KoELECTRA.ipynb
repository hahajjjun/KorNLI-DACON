{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KoELECTRA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV1suFk-DPXa",
        "outputId": "dc212e01-2a91-4d57-e4ac-a53259bb8db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EtqIpxnDTvm",
        "outputId": "e0bbd4dc-5742-4513-a093-0b0a6defeeab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 60.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tqdm import tqdm\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Vvo_vqNqEr8Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Seed Fix\n",
        "import random\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  \n",
        "    torch.backends.cudnn.deterministic = True  \n",
        "    torch.backends.cudnn.benchmark = True  \n",
        "seed_everything()"
      ],
      "metadata": {
        "id": "HFjgPSh8E0H_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "u5VAv2AlE6zn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# HYPERPARMS ##############\n",
        "num_epochs = 5\n",
        "batch_size =128\n",
        "lr = 0.00001\n",
        "pretrain = \"monologg/koelectra-base-v3-discriminator\""
      ],
      "metadata": {
        "id": "O1xjHfahF8u3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  TRAIN = os.path.join(path, 'train_data.csv')\n",
        "  TEST = os.path.join(path, 'test_data.csv')\n",
        "  SS = os.path.join(path, 'sample_submission.csv')\n",
        "  label_dict = {\"entailment\" : 0, \"contradiction\" : 1, \"neutral\" : 2}\n",
        "  train = pd.read_csv(TRAIN)\n",
        "  test = pd.read_csv(TEST)\n",
        "  sample_submission = pd.read_csv(SS)\n",
        "  train['label'] = train['label'].map(label_dict)\n",
        "\n",
        "  return train,test,sample_submission\n",
        "\n",
        "def text_clean(df):\n",
        "  df[\"premise_\"] = \"[CLS]\" + df[\"premise\"] + \"[SEP]\"\n",
        "  df[\"hypothesis_\"] = df[\"hypothesis\"] + \"[SEP]\"\n",
        "  df[\"text_sum\"] = df.premise_ + \" \" + df.hypothesis_\n",
        "  df = df[['text_sum','label']]\n",
        "  return df \n",
        "\n",
        "ROOT = '/content/drive/MyDrive/DACON_MONTHLYNLI'\n",
        "train,test,sample_submission = load_data(ROOT)\n",
        "clean_train,clean_test  = text_clean(train),text_clean(test)"
      ],
      "metadata": {
        "id": "UH2mpAvEGGjH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# Dataset ##############\n",
        "class CustomDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,dataset,option):\n",
        "    \n",
        "    self.dataset = dataset \n",
        "    self.option = option\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(pretrain)\n",
        "\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    row = self.dataset.iloc[idx, 0:2].values\n",
        "    text = row[0]\n",
        "    #y = row[1]\n",
        "\n",
        "    inputs = self.tokenizer(\n",
        "        text, \n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=70,\n",
        "        pad_to_max_length=True,\n",
        "        add_special_tokens=False\n",
        "        )\n",
        "    \n",
        "    input_ids = inputs['input_ids'][0]\n",
        "    attention_mask = inputs['attention_mask'][0]\n",
        "    \n",
        "    if self.option =='train':\n",
        "        y =row[1]\n",
        "        return input_ids,attention_mask,y\n",
        "\n",
        "    return input_ids, attention_mask"
      ],
      "metadata": {
        "id": "sHvnbUVQKXRr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############### CV ################\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits = 5,shuffle=True,random_state=42)\n",
        "folds=[]\n",
        "for trn_idx,val_idx in skf.split(clean_train['text_sum'],clean_train['label']):\n",
        "    folds.append((trn_idx,val_idx))"
      ],
      "metadata": {
        "id": "7taP1jaYL1WU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = []\n",
        "\n",
        "for i,fold in enumerate(range(5)):\n",
        "    print('===============',i+1,'fold start===============')\n",
        "    model = ElectraForSequenceClassification.from_pretrained(pretrain,num_labels=3).to(device)\n",
        "    model=nn.DataParallel(model).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    \n",
        "    train_idx = folds[fold][0]\n",
        "    valid_idx = folds[fold][1]\n",
        "    train_data = clean_train.loc[trn_idx]\n",
        "    val_data = clean_train.loc[valid_idx]\n",
        "    train_dataset = CustomDataset(train_data,'train')\n",
        "    valid_dataset = CustomDataset(val_data,'train')\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "    warmup_ratio = 0.1\n",
        "    total_steps = len(train_loader) * num_epochs\n",
        "    warmup_step = int(total_steps * warmup_ratio)\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1, num_training_steps=total_steps)\n",
        "    valid_loss_min = 0.4\n",
        "    valid_acc_max = 0.8\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        batches = 0\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total =0\n",
        "        model.train()\n",
        "        \n",
        "        for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(input_ids_batch.to(device), attention_mask = attention_masks_batch.to(device))[0]\n",
        "            loss = F.cross_entropy(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(y_pred, 1)\n",
        "            correct += (predicted == y_batch).sum()\n",
        "            total += len(y_batch)\n",
        "            batches += 1\n",
        "            if batches % 100 == 0:\n",
        "                print(\"Batch Loss: \", total_loss, \"Accuracy: \", correct.float() / total)\n",
        "      \n",
        "        val_loss = []\n",
        "        val_acc = []\n",
        "        \n",
        "        for input_ids_batch, attention_masks_batch, y_batch in tqdm(valid_loader):\n",
        "            \n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                \n",
        "                y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "                valid_loss = F.cross_entropy(y_pred,y_batch.to(device)).cpu().detach().numpy()\n",
        "\n",
        "                preds = torch.argmax(y_pred,1)\n",
        "                preds = preds.cpu().detach().numpy()\n",
        "                y_batch = y_batch.cpu().detach().numpy()\n",
        "                batch_acc = (preds==y_batch).mean()\n",
        "                val_loss.append(valid_loss)\n",
        "                val_acc.append(batch_acc)\n",
        "                \n",
        "                \n",
        "        val_loss = np.mean(val_loss)\n",
        "        val_acc = np.mean(val_acc)\n",
        "        scheduler.step()\n",
        "        print(f'Epoch: {epoch} - valid Loss: {val_loss:.6f} - valid_acc : {val_acc:.6f}')\n",
        "        print(optimizer.param_groups[0][\"lr\"])\n",
        "        if valid_acc_max < val_acc:\n",
        "            valid_acc_max = val_acc\n",
        "            best_models.append(model)\n",
        "            torch.save(model, f'koelectra-{len(best_models)}.pth') \n",
        "            print('model save, model val acc : ',val_acc)\n",
        "            print('best_models size : ',len(best_models))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekgRjI7KMFIA",
        "outputId": "4f373162-6449-4e55-a3a7-e35eadccfae5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== 1 fold start===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  109.82958447933197 Accuracy:  tensor(0.3351, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:53<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 - valid Loss: 1.099186 - valid_acc : 0.329492\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:30<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  86.87953099608421 Accuracy:  tensor(0.6357, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 - valid Loss: 0.373736 - valid_acc : 0.878125\n",
            "9.999959857256764e-06\n",
            "model save, model val acc :  0.878125\n",
            "best_models size :  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  39.549238085746765 Accuracy:  tensor(0.8607, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 - valid Loss: 0.240497 - valid_acc : 0.926172\n",
            "9.999839429671632e-06\n",
            "model save, model val acc :  0.926171875\n",
            "best_models size :  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:30<01:30,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  27.69295635819435 Accuracy:  tensor(0.9105, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:55<00:00,  1.50s/it]\n",
            "100%|██████████| 40/40 [00:23<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 - valid Loss: 0.150744 - valid_acc : 0.960156\n",
            "9.99963871917832e-06\n",
            "model save, model val acc :  0.96015625\n",
            "best_models size :  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:30<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  22.35672189295292 Accuracy:  tensor(0.9295, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 - valid Loss: 0.103663 - valid_acc : 0.973437\n",
            "9.999357728999657e-06\n",
            "model save, model val acc :  0.9734375\n",
            "best_models size :  4\n",
            "=============== 2 fold start===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 64%|██████▎   | 100/157 [02:30<01:25,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  109.85369527339935 Accuracy:  tensor(0.3387, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 - valid Loss: 1.098797 - valid_acc : 0.334766\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  89.6503210067749 Accuracy:  tensor(0.6136, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 - valid Loss: 0.398754 - valid_acc : 0.868555\n",
            "9.999959857256764e-06\n",
            "model save, model val acc :  0.8685546875\n",
            "best_models size :  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  40.140067636966705 Accuracy:  tensor(0.8620, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 - valid Loss: 0.265000 - valid_acc : 0.918359\n",
            "9.999839429671632e-06\n",
            "model save, model val acc :  0.918359375\n",
            "best_models size :  6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  29.161745637655258 Accuracy:  tensor(0.9027, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 - valid Loss: 0.177499 - valid_acc : 0.948828\n",
            "9.99963871917832e-06\n",
            "model save, model val acc :  0.948828125\n",
            "best_models size :  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  21.272604323923588 Accuracy:  tensor(0.9332, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:53<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 - valid Loss: 0.126331 - valid_acc : 0.966016\n",
            "9.999357728999657e-06\n",
            "model save, model val acc :  0.966015625\n",
            "best_models size :  8\n",
            "=============== 3 fold start===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  110.18184506893158 Accuracy:  tensor(0.3280, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:53<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 - valid Loss: 1.101412 - valid_acc : 0.317773\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  92.63584923744202 Accuracy:  tensor(0.5709, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 - valid Loss: 0.402408 - valid_acc : 0.861523\n",
            "9.999959857256764e-06\n",
            "model save, model val acc :  0.8615234375\n",
            "best_models size :  9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  40.747379302978516 Accuracy:  tensor(0.8583, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 - valid Loss: 0.268712 - valid_acc : 0.912500\n",
            "9.999839429671632e-06\n",
            "model save, model val acc :  0.9125\n",
            "best_models size :  10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  28.86037975549698 Accuracy:  tensor(0.9040, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 - valid Loss: 0.179030 - valid_acc : 0.947656\n",
            "9.99963871917832e-06\n",
            "model save, model val acc :  0.94765625\n",
            "best_models size :  11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:30<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  21.935907907783985 Accuracy:  tensor(0.9287, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 - valid Loss: 0.116279 - valid_acc : 0.967578\n",
            "9.999357728999657e-06\n",
            "model save, model val acc :  0.967578125\n",
            "best_models size :  12\n",
            "=============== 4 fold start===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 64%|██████▎   | 100/157 [02:29<01:24,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  110.36125636100769 Accuracy:  tensor(0.3148, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:53<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 - valid Loss: 1.104044 - valid_acc : 0.315876\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  90.4092509150505 Accuracy:  tensor(0.5788, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 - valid Loss: 0.414693 - valid_acc : 0.857171\n",
            "9.999959857256764e-06\n",
            "model save, model val acc :  0.8571707589285715\n",
            "best_models size :  13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  41.478720009326935 Accuracy:  tensor(0.8546, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 - valid Loss: 0.248719 - valid_acc : 0.916406\n",
            "9.999839429671632e-06\n",
            "model save, model val acc :  0.91640625\n",
            "best_models size :  14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  29.290293276309967 Accuracy:  tensor(0.9022, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 - valid Loss: 0.171333 - valid_acc : 0.946484\n",
            "9.99963871917832e-06\n",
            "model save, model val acc :  0.946484375\n",
            "best_models size :  15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  22.315836288034916 Accuracy:  tensor(0.9273, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:53<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 - valid Loss: 0.103948 - valid_acc : 0.970313\n",
            "9.999357728999657e-06\n",
            "model save, model val acc :  0.9703125\n",
            "best_models size :  16\n",
            "=============== 5 fold start===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 64%|██████▎   | 100/157 [02:30<01:24,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  110.00235271453857 Accuracy:  tensor(0.3355, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:53<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 - valid Loss: 1.099312 - valid_acc : 0.359096\n",
            "1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  88.18478208780289 Accuracy:  tensor(0.6120, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 - valid Loss: 0.459035 - valid_acc : 0.838030\n",
            "9.999959857256764e-06\n",
            "model save, model val acc :  0.8380301339285715\n",
            "best_models size :  17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  40.47463580965996 Accuracy:  tensor(0.8595, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 - valid Loss: 0.384307 - valid_acc : 0.866546\n",
            "9.999839429671632e-06\n",
            "model save, model val acc :  0.8665457589285716\n",
            "best_models size :  18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:29<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  28.322804048657417 Accuracy:  tensor(0.9059, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 - valid Loss: 0.380741 - valid_acc : 0.869085\n",
            "9.99963871917832e-06\n",
            "model save, model val acc :  0.8690848214285716\n",
            "best_models size :  19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 100/157 [02:30<01:25,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Loss:  21.39881782978773 Accuracy:  tensor(0.9309, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [03:54<00:00,  1.49s/it]\n",
            "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 - valid Loss: 0.385521 - valid_acc : 0.873577\n",
            "9.999357728999657e-06\n",
            "model save, model val acc :  0.8735770089285715\n",
            "best_models size :  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# koelectra-4k번 모델이 가장 성능이 좋은 것으로 가정\n",
        "test_dataset = CustomDataset(clean_test,'test')\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
        "\n",
        "preds = dict()\n",
        "for idx, m in enumerate(best_models):\n",
        "    if (idx+1) % 4 == 0:\n",
        "      print(f'{idx+1} 번째 모델 예측 진행중')\n",
        "      bestm = m\n",
        "      bestm.eval()\n",
        "      answer = []\n",
        "      with torch.no_grad():\n",
        "          for input_ids_batch, attention_masks_batch in tqdm(test_loader):\n",
        "              y_pred = bestm(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0].detach().cpu().numpy()\n",
        "              answer.extend(y_pred)\n",
        "      preds[idx+1] = answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBtUdmEj-l-N",
        "outputId": "681396a6-25aa-462d-cc26-dbbbd5465a8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 번째 모델 예측 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:07<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 번째 모델 예측 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:07<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 번째 모델 예측 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:07<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 번째 모델 예측 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:07<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 번째 모델 예측 진행중\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:08<00:00,  3.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "for key in preds.keys():\n",
        "  df = pd.concat([df, pd.DataFrame(np.array(preds[key]))], axis =1 )\n",
        "df.columns = [i for i in range(3*5)]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "3-dLfbH6Ziow",
        "outputId": "ffb7ab12-b9d7-4520-b3d0-3f5b66e44c4b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ba4083f-3fe4-4f3a-aa1b-312b6a707038\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.813181</td>\n",
              "      <td>3.790997</td>\n",
              "      <td>-1.812176</td>\n",
              "      <td>-1.720752</td>\n",
              "      <td>3.570578</td>\n",
              "      <td>-1.937155</td>\n",
              "      <td>-1.712877</td>\n",
              "      <td>3.756066</td>\n",
              "      <td>-1.933276</td>\n",
              "      <td>-2.062337</td>\n",
              "      <td>3.668516</td>\n",
              "      <td>-1.805922</td>\n",
              "      <td>-1.981519</td>\n",
              "      <td>3.389702</td>\n",
              "      <td>-1.821765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.082987</td>\n",
              "      <td>-1.965420</td>\n",
              "      <td>2.308169</td>\n",
              "      <td>0.002843</td>\n",
              "      <td>-2.154179</td>\n",
              "      <td>2.360120</td>\n",
              "      <td>-0.327420</td>\n",
              "      <td>-2.401240</td>\n",
              "      <td>2.605109</td>\n",
              "      <td>-0.093013</td>\n",
              "      <td>-2.719182</td>\n",
              "      <td>2.769421</td>\n",
              "      <td>-0.062618</td>\n",
              "      <td>-2.263453</td>\n",
              "      <td>2.627895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.749909</td>\n",
              "      <td>-2.242893</td>\n",
              "      <td>1.537016</td>\n",
              "      <td>2.553719</td>\n",
              "      <td>-2.144502</td>\n",
              "      <td>-0.164674</td>\n",
              "      <td>2.476145</td>\n",
              "      <td>-2.435955</td>\n",
              "      <td>-0.384265</td>\n",
              "      <td>0.788575</td>\n",
              "      <td>-2.690581</td>\n",
              "      <td>1.867146</td>\n",
              "      <td>2.160340</td>\n",
              "      <td>-2.659138</td>\n",
              "      <td>0.019321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.165525</td>\n",
              "      <td>3.519262</td>\n",
              "      <td>-1.113425</td>\n",
              "      <td>-2.150406</td>\n",
              "      <td>3.448496</td>\n",
              "      <td>-1.279370</td>\n",
              "      <td>-1.688352</td>\n",
              "      <td>3.543314</td>\n",
              "      <td>-1.662793</td>\n",
              "      <td>-2.727901</td>\n",
              "      <td>3.360396</td>\n",
              "      <td>-0.711315</td>\n",
              "      <td>-2.270495</td>\n",
              "      <td>3.052619</td>\n",
              "      <td>-0.945890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.083742</td>\n",
              "      <td>1.967190</td>\n",
              "      <td>-1.975008</td>\n",
              "      <td>0.350241</td>\n",
              "      <td>1.986103</td>\n",
              "      <td>-2.371563</td>\n",
              "      <td>-0.147538</td>\n",
              "      <td>2.298349</td>\n",
              "      <td>-2.104549</td>\n",
              "      <td>-0.433285</td>\n",
              "      <td>2.022959</td>\n",
              "      <td>-1.663125</td>\n",
              "      <td>-0.197520</td>\n",
              "      <td>1.723815</td>\n",
              "      <td>-2.031419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>-1.627669</td>\n",
              "      <td>-1.647104</td>\n",
              "      <td>3.591126</td>\n",
              "      <td>-1.384216</td>\n",
              "      <td>-1.830634</td>\n",
              "      <td>3.525597</td>\n",
              "      <td>-1.801290</td>\n",
              "      <td>-1.598683</td>\n",
              "      <td>3.555557</td>\n",
              "      <td>-1.023092</td>\n",
              "      <td>-2.277959</td>\n",
              "      <td>3.400325</td>\n",
              "      <td>-1.537982</td>\n",
              "      <td>-1.589641</td>\n",
              "      <td>3.705833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>-0.015603</td>\n",
              "      <td>-2.407104</td>\n",
              "      <td>2.783002</td>\n",
              "      <td>0.863470</td>\n",
              "      <td>-2.353145</td>\n",
              "      <td>1.929824</td>\n",
              "      <td>0.423998</td>\n",
              "      <td>-2.627591</td>\n",
              "      <td>2.029228</td>\n",
              "      <td>0.666282</td>\n",
              "      <td>-2.513784</td>\n",
              "      <td>1.693954</td>\n",
              "      <td>0.458724</td>\n",
              "      <td>-2.505109</td>\n",
              "      <td>2.226074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1663</th>\n",
              "      <td>-0.482072</td>\n",
              "      <td>-2.263233</td>\n",
              "      <td>3.078904</td>\n",
              "      <td>0.503921</td>\n",
              "      <td>-2.433107</td>\n",
              "      <td>2.378650</td>\n",
              "      <td>-0.612951</td>\n",
              "      <td>-2.443218</td>\n",
              "      <td>3.004122</td>\n",
              "      <td>0.462184</td>\n",
              "      <td>-2.902555</td>\n",
              "      <td>2.467948</td>\n",
              "      <td>-0.371765</td>\n",
              "      <td>-2.345434</td>\n",
              "      <td>3.127222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1664</th>\n",
              "      <td>-1.175655</td>\n",
              "      <td>-2.110607</td>\n",
              "      <td>3.655845</td>\n",
              "      <td>-1.044451</td>\n",
              "      <td>-2.146047</td>\n",
              "      <td>3.555725</td>\n",
              "      <td>-1.488245</td>\n",
              "      <td>-1.955118</td>\n",
              "      <td>3.518110</td>\n",
              "      <td>-0.855425</td>\n",
              "      <td>-2.385209</td>\n",
              "      <td>3.310996</td>\n",
              "      <td>-1.172345</td>\n",
              "      <td>-1.978459</td>\n",
              "      <td>3.751168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>-1.348619</td>\n",
              "      <td>-0.518488</td>\n",
              "      <td>2.032226</td>\n",
              "      <td>-1.402763</td>\n",
              "      <td>-0.456815</td>\n",
              "      <td>2.048691</td>\n",
              "      <td>-1.844845</td>\n",
              "      <td>-0.753890</td>\n",
              "      <td>2.767817</td>\n",
              "      <td>-1.697835</td>\n",
              "      <td>0.307813</td>\n",
              "      <td>1.371884</td>\n",
              "      <td>-0.981145</td>\n",
              "      <td>-1.036041</td>\n",
              "      <td>2.307045</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1666 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ba4083f-3fe4-4f3a-aa1b-312b6a707038')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ba4083f-3fe4-4f3a-aa1b-312b6a707038 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ba4083f-3fe4-4f3a-aa1b-312b6a707038');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2   ...        12        13        14\n",
              "0    -1.813181  3.790997 -1.812176  ... -1.981519  3.389702 -1.821765\n",
              "1    -0.082987 -1.965420  2.308169  ... -0.062618 -2.263453  2.627895\n",
              "2     0.749909 -2.242893  1.537016  ...  2.160340 -2.659138  0.019321\n",
              "3    -2.165525  3.519262 -1.113425  ... -2.270495  3.052619 -0.945890\n",
              "4     0.083742  1.967190 -1.975008  ... -0.197520  1.723815 -2.031419\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "1661 -1.627669 -1.647104  3.591126  ... -1.537982 -1.589641  3.705833\n",
              "1662 -0.015603 -2.407104  2.783002  ...  0.458724 -2.505109  2.226074\n",
              "1663 -0.482072 -2.263233  3.078904  ... -0.371765 -2.345434  3.127222\n",
              "1664 -1.175655 -2.110607  3.655845  ... -1.172345 -1.978459  3.751168\n",
              "1665 -1.348619 -0.518488  2.032226  ... -0.981145 -1.036041  2.307045\n",
              "\n",
              "[1666 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softvoted_prediction = "
      ],
      "metadata": {
        "id": "X94AJMnjZt_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(saved_models/)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR7OXQlwbwCK",
        "outputId": "c21400c4-7798-424f-8e56-55de58a7993a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data  saved_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r saved_models.zip saved_models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTMfUNrGcOfQ",
        "outputId": "e69be62b-11ae-45bf-896b-3315c1ddac2e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: saved_models/ (stored 0%)\n",
            "  adding: saved_models/koelectra-9.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-12.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-1.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-19.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-11.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-7.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-20.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-6.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-13.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-16.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-8.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-10.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-17.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-15.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-2.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-18.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-14.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-3.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-4.pth (deflated 8%)\n",
            "  adding: saved_models/koelectra-5.pth (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NbAOgKrAcguJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}