{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltroKKTXdwlY",
        "outputId": "11e5de01-51ae-4b70-c6aa-a619917f93a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEAqN-r2d0nM",
        "outputId": "b75922b4-05c6-4bf1-d063-dfe1341d21d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbt7mQzTd4Ff"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tqdm import tqdm\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFjgPSh8E0H_"
      },
      "outputs": [],
      "source": [
        "# Random Seed Fix\n",
        "import random\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  \n",
        "    torch.backends.cudnn.deterministic = True  \n",
        "    torch.backends.cudnn.benchmark = True  \n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5VAv2AlE6zn"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1xjHfahF8u3"
      },
      "outputs": [],
      "source": [
        "############# HYPERPARMS ##############\n",
        "num_epochs = 5\n",
        "batch_size =128\n",
        "lr = 0.00001\n",
        "pretrain = \"monologg/koelectra-base-v3-discriminator\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH2mpAvEGGjH"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "  TRAIN = os.path.join(path, 'benchmark_train_data.csv')\n",
        "  TEST = os.path.join(path, 'test_data.csv')\n",
        "  SS = os.path.join(path, 'sample_submission.csv')\n",
        "  label_dict = {\"entailment\" : 0, \"contradiction\" : 1, \"neutral\" : 2}\n",
        "  train = pd.read_csv(TRAIN)\n",
        "  test = pd.read_csv(TEST)\n",
        "  sample_submission = pd.read_csv(SS)\n",
        "  train['label'] = train['label'].map(label_dict)\n",
        "\n",
        "  return train,test,sample_submission\n",
        "\n",
        "def text_clean(df):\n",
        "  df[\"premise_\"] = \"[CLS]\" + df[\"premise\"] + \"[SEP]\"\n",
        "  df[\"hypothesis_\"] = df[\"hypothesis\"] + \"[SEP]\"\n",
        "  df[\"text_sum\"] = df.premise_ + \" \" + df.hypothesis_\n",
        "  df = df[['text_sum','label']]\n",
        "  return df \n",
        "\n",
        "ROOT = '/content/drive/MyDrive/DACON_MONTHLYNLI'\n",
        "#ROOT = '/content/drive/Shareddrives/Dacon/data'\n",
        "train,test,sample_submission = load_data(ROOT)\n",
        "clean_train,clean_test  = text_clean(train),text_clean(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHvnbUVQKXRr"
      },
      "outputs": [],
      "source": [
        "############# Dataset ##############\n",
        "class CustomDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,dataset,option):\n",
        "    \n",
        "    self.dataset = dataset \n",
        "    self.option = option\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(pretrain)\n",
        "\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    row = self.dataset.iloc[idx, 0:2].values\n",
        "    text = row[0]\n",
        "    #y = row[1]\n",
        "\n",
        "    inputs = self.tokenizer(\n",
        "        text, \n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=70,\n",
        "        pad_to_max_length=True,\n",
        "        add_special_tokens=False\n",
        "        )\n",
        "    \n",
        "    input_ids = inputs['input_ids'][0]\n",
        "    attention_mask = inputs['attention_mask'][0]\n",
        "    \n",
        "    if self.option =='train':\n",
        "        y =row[1]\n",
        "        return input_ids,attention_mask,y\n",
        "\n",
        "    return input_ids, attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fko1n2OkeHMZ",
        "outputId": "644212e4-0a68-4fd3-e37b-3c1be1b8c192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:14<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:14<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:14<00:00,  1.84it/s]\n"
          ]
        }
      ],
      "source": [
        "# koelectra-4k번 모델이 가장 성능이 좋은 것으로 가정\n",
        "model = ElectraForSequenceClassification.from_pretrained(pretrain,num_labels=3).to(device)\n",
        "#model=nn.DataParallel(model).to(device)\n",
        "test_dataset = CustomDataset(clean_test,'test')\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
        "\n",
        "model_ROOT = '/content/drive/MyDrive/DACON_MONTHLYNLI/models/koelectra(benchmarked)'\n",
        "model_PATHs = [os.path.join(model_ROOT, 'koelectra-4.pth'), os.path.join(model_ROOT, 'koelectra-8.pth'), os.path.join(model_ROOT, 'koelectra-12.pth')]\n",
        "\n",
        "preds = dict()\n",
        "for pth in model_PATHs:\n",
        "    print(pth[-5:])\n",
        "    currentm = model\n",
        "    currentm.load_state_dict(torch.load(pth).module.state_dict())\n",
        "    currentm.eval()\n",
        "    answer = []\n",
        "    with torch.no_grad():\n",
        "        for input_ids_batch, attention_masks_batch in tqdm(test_loader):\n",
        "            y_pred = currentm(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0].detach().cpu().numpy()\n",
        "            answer.extend(y_pred)\n",
        "    preds[pth[-5]] = answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-KuH104hH8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6b1f734f-df7e-4e7f-a7cd-d98a937b7321"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8f0725b8-40a1-4304-a3fb-c031e96028a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4_0</th>\n",
              "      <th>4_1</th>\n",
              "      <th>4_2</th>\n",
              "      <th>8_0</th>\n",
              "      <th>8_1</th>\n",
              "      <th>8_2</th>\n",
              "      <th>12_0</th>\n",
              "      <th>12_1</th>\n",
              "      <th>12_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.004339</td>\n",
              "      <td>0.989957</td>\n",
              "      <td>0.005704</td>\n",
              "      <td>0.003115</td>\n",
              "      <td>0.993447</td>\n",
              "      <td>0.003437</td>\n",
              "      <td>0.003267</td>\n",
              "      <td>0.992312</td>\n",
              "      <td>0.004421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.053540</td>\n",
              "      <td>0.005561</td>\n",
              "      <td>0.940898</td>\n",
              "      <td>0.405675</td>\n",
              "      <td>0.014389</td>\n",
              "      <td>0.579936</td>\n",
              "      <td>0.102595</td>\n",
              "      <td>0.006492</td>\n",
              "      <td>0.890913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.613809</td>\n",
              "      <td>0.010409</td>\n",
              "      <td>0.375782</td>\n",
              "      <td>0.705776</td>\n",
              "      <td>0.013020</td>\n",
              "      <td>0.281204</td>\n",
              "      <td>0.584750</td>\n",
              "      <td>0.015179</td>\n",
              "      <td>0.400070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003056</td>\n",
              "      <td>0.906573</td>\n",
              "      <td>0.090371</td>\n",
              "      <td>0.002320</td>\n",
              "      <td>0.989104</td>\n",
              "      <td>0.008576</td>\n",
              "      <td>0.003008</td>\n",
              "      <td>0.987799</td>\n",
              "      <td>0.009193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011893</td>\n",
              "      <td>0.978237</td>\n",
              "      <td>0.009870</td>\n",
              "      <td>0.031735</td>\n",
              "      <td>0.959900</td>\n",
              "      <td>0.008365</td>\n",
              "      <td>0.010683</td>\n",
              "      <td>0.979891</td>\n",
              "      <td>0.009426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>0.005877</td>\n",
              "      <td>0.004433</td>\n",
              "      <td>0.989691</td>\n",
              "      <td>0.005544</td>\n",
              "      <td>0.004134</td>\n",
              "      <td>0.990321</td>\n",
              "      <td>0.004064</td>\n",
              "      <td>0.004816</td>\n",
              "      <td>0.991120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>0.492611</td>\n",
              "      <td>0.008447</td>\n",
              "      <td>0.498942</td>\n",
              "      <td>0.225914</td>\n",
              "      <td>0.008708</td>\n",
              "      <td>0.765378</td>\n",
              "      <td>0.100834</td>\n",
              "      <td>0.005882</td>\n",
              "      <td>0.893284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1663</th>\n",
              "      <td>0.038510</td>\n",
              "      <td>0.003807</td>\n",
              "      <td>0.957682</td>\n",
              "      <td>0.072953</td>\n",
              "      <td>0.006287</td>\n",
              "      <td>0.920760</td>\n",
              "      <td>0.069169</td>\n",
              "      <td>0.016159</td>\n",
              "      <td>0.914672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1664</th>\n",
              "      <td>0.006247</td>\n",
              "      <td>0.004053</td>\n",
              "      <td>0.989700</td>\n",
              "      <td>0.006821</td>\n",
              "      <td>0.003116</td>\n",
              "      <td>0.990064</td>\n",
              "      <td>0.004323</td>\n",
              "      <td>0.003225</td>\n",
              "      <td>0.992452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>0.016716</td>\n",
              "      <td>0.032517</td>\n",
              "      <td>0.950767</td>\n",
              "      <td>0.033902</td>\n",
              "      <td>0.029741</td>\n",
              "      <td>0.936357</td>\n",
              "      <td>0.019158</td>\n",
              "      <td>0.056645</td>\n",
              "      <td>0.924197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1666 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f0725b8-40a1-4304-a3fb-c031e96028a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f0725b8-40a1-4304-a3fb-c031e96028a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f0725b8-40a1-4304-a3fb-c031e96028a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           4_0       4_1       4_2  ...      12_0      12_1      12_2\n",
              "0     0.004339  0.989957  0.005704  ...  0.003267  0.992312  0.004421\n",
              "1     0.053540  0.005561  0.940898  ...  0.102595  0.006492  0.890913\n",
              "2     0.613809  0.010409  0.375782  ...  0.584750  0.015179  0.400070\n",
              "3     0.003056  0.906573  0.090371  ...  0.003008  0.987799  0.009193\n",
              "4     0.011893  0.978237  0.009870  ...  0.010683  0.979891  0.009426\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "1661  0.005877  0.004433  0.989691  ...  0.004064  0.004816  0.991120\n",
              "1662  0.492611  0.008447  0.498942  ...  0.100834  0.005882  0.893284\n",
              "1663  0.038510  0.003807  0.957682  ...  0.069169  0.016159  0.914672\n",
              "1664  0.006247  0.004053  0.989700  ...  0.004323  0.003225  0.992452\n",
              "1665  0.016716  0.032517  0.950767  ...  0.019158  0.056645  0.924197\n",
              "\n",
              "[1666 rows x 9 columns]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "### SINGLE PREDICTION FOR CONCORDANCE OBSERVATION ###\n",
        "single_preds = dict()\n",
        "concat_probs = pd.DataFrame()\n",
        "temp = np.zeros((1666, 3))\n",
        "for key in preds.keys():\n",
        "  x = np.array(preds[key])\n",
        "  max = np.max(x,axis=1,keepdims=True) #returns max of each row and keeps same dims\n",
        "  e_x = np.exp(x - max) #subtracts each row with its max value\n",
        "  sum = np.sum(e_x,axis=1,keepdims=True) #returns sum of each row and keeps same dims\n",
        "  f_x = e_x / sum\n",
        "  #single_preds['prob_'+str(key)] = pd.DataFrame(f_x)\n",
        "  single_preds['pred_'+str(key)] = pd.DataFrame(np.argmax(f_x, axis=1))\n",
        "  concat_probs = pd.concat([concat_probs, pd.DataFrame(f_x)], axis =1)\n",
        "columns = []\n",
        "\n",
        "for j in range(1,4):\n",
        "  for i in range(3):\n",
        "    column = f\"{4*j}_{i}\"\n",
        "    columns.append(column)\n",
        "concat_probs.columns = columns\n",
        "display(concat_probs)\n",
        "concat_probs.to_csv('submission_KoELECTRA_soft.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ENSEMBLED PREDICTION ###\n",
        "temp = np.zeros((1666, 3))\n",
        "for key in preds.keys():\n",
        "  x = np.array(preds[key])\n",
        "  max = np.max(x,axis=1,keepdims=True) #returns max of each row and keeps same dims\n",
        "  e_x = np.exp(x - max) #subtracts each row with its max value\n",
        "  sum = np.sum(e_x,axis=1,keepdims=True) #returns sum of each row and keeps same dims\n",
        "  f_x = e_x / sum \n",
        "  temp += f_x\n",
        "temp = temp/5\n",
        "softvoted_prob = pd.DataFrame(temp)\n",
        "softvoted_pred = pd.DataFrame(np.argmax(temp, axis=1))\n",
        "decode_map = {0 : \"entailment\" , 1 :  \"contradiction\" , 2 : \"neutral\" }\n",
        "sample_submission['label'] = softvoted_pred\n",
        "sample_submission['label'] = sample_submission['label'].map(decode_map)\n",
        "sample_submission.to_csv('submission_KoELECTRA.csv', index = False)"
      ],
      "metadata": {
        "id": "RoCsF4qnOKTd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KoELECTRA_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}